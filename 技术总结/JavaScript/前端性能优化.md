# 前端性能优化

## 网络层面

### 请求过程的优化

在浏览器，从输入`URL`到页面加载的过程简述：

`DNS`解析 → `TCP`连接 → `HTTP`请求抛出 → 服务器处理请求，`HTTP`响应返回 → 浏览器拿到响应数据，解析内容，把解析结果渲染出来

#### HTTP请求优化

##### HTTP层面优化

+ `DNS`解析

    `DNS` 实现域名到IP的映射。通过域名访问站点，每次请求都要做`DNS`解析。目前每次`DNS`解析，通常在`200ms`以下。一般采用`DNS Prefetch` 一种`DNS` 预解析技术，当你浏览网页时，浏览器会在加载网页时对网页中的域名进行解析缓存，这样在你单击当前网页中的连接时就无需进行`DNS`的解析，减少用户等待时间，提高用户体验。

    ```html
    <!-- 只有部分浏览器支持 -->
    <link rel="dns-prefetch" href="www.baidu.com" />  
    ```

+ `TCP`连接

    采用`http2.0`，可以复用`tcp`通道，采用二进制格式而非文本格式，使用报头压缩，`HTTP/2`降低了开销，支持`cache push`

+ 浏览器并发

    基于端口跟线程切换开销，浏览器不可能无限的并发请求。`chrome`的并发为6，超过限制数目的请求就会被阻塞；

+ http请求次数
    
    减少`http`的请求次数，将多个请求合并成同一个，减少`http`的开销

+ 构建工具性能调试

    [webpack](https://segmentfault.com/a/1190000021494964?utm_source=tag-newest)：充分利用webpack提供给我们的能力，利用[DllPlugin](https://segmentfault.com/a/1190000016567986)与[CommonsChunkPlugin](https://segmentfault.com/a/1190000012828879)等插件对我们代码进行优化，文件的分割与合并，公共代码的提取，长缓存等策略，

    - `DllPlugin`：把复用性较高的第三方模块打包到动态链接库中，在不升级这些库的情况下，动态库不需要重新打包，每次构建只重新打包业务代码。
    - `CommonsChunkPlugin`:：提取第三方库和公共模块，避免首屏加载的`bundle`文件或者按需加载的`bundle`文件体积过大，从而导致加载时间过长

+ HTTP压缩
  
    [Gzip压缩](https://segmentfault.com/a/1190000012571492)：`HTTP` 压缩就是以缩小体积为目的，对 `HTTP` 内容进行重新编码的过程，原理是找出一些重复出现的字符串、临时替换它们，从而使整个文件变小，文件中代码的重复率越高，那么压缩的效率就越高，使用 `Gzip` 的收益也就越大

+ 图片优化

    + `JPEG/JPG`：
      - 优点：体积小
      - 缺点：不支持透明，有损压缩，压缩图片模糊明显
      - 应用场景：背景图、轮播图等

    + `PNG-8/PNG-24`：
      - 优点：无损压缩，色彩表现力强
      - 缺点：体积大
      - 应用场景：小`logo`，颜色简单对比强烈的图片或者背景

    + `SVG`：
      - 优点：文本文件，体积更小，压缩性更强，图片可以无限放大不失真，兼容性好
      - 缺点：渲染成本高
      - 应用场景：可直接在代码中，使用`.svg`的独立文件，`icon-font`

    + `Base64`：
      - 优点：文本文件，以来编码结果写入`HTML`或者`CSS`中，减少请求次数
      - 缺点：`Base64`编码后的图片大小会膨胀为原来的4/3
      - 应用场景：小图标，非常小的`logo`

    + `WebP`：
      - 优点：细节丰富，支持透明、动图，同比体积更小
      - 缺点：兼容性较差
      - 应用场景：

### 减少网络请求

#### 本地存储

+ 浏览器缓存机制

    + 强缓存：浏览器在请求某一资源时，会先获取该资源缓存的`header`信息，判断是否命中强缓存（`cache-control`和`expires`信息），若命中直接从缓存中获取资源信息，包括缓存`header`信息；本次请求根本就不会与服务器进行通信
      - `expires`:这是`http1.0`时的规范；它的值为一个绝对时间的GMT格式的时间字符串，如`Mon, 10 Jun 2015 21:31:12 GMT`，如果发送请求的时间在`expires`之前，那么本地缓存始终有效，否则就会发送请求到服务器来获取资源
      
      - `cache-control`：`max-age=number`，这是`http1.1`时出现的`header`信息，主要是利用该字段的`max-age`值来进行判断，它是一个相对值；资源第一次的请求时间和`Cache-Control`设定的有效期，计算出一个资源过期时间，再拿这个过期时间跟当前的请求时间比较，如果请求时间在过期时间之前，就能命中缓存，否则就不行；`cache-control`除了该字段外，还有下面几个比较常用的设置值：`no-cache` ，`no-store`，`public`，`private`

    + 协商缓存：
      - `Last-Modified/If-Modified-Since`:第一次请求，服务端在`Response Headers：Last-Modified:Fri, 27 Oct 2017 06:35:57 GMT`，也就是服务端最后修改该资源的时间。浏览器再次跟服务器请求这个资源时，在`request`的`header`上加上`If-Modified-Since`的`header`，这个`header`的值就是上一次请求时返回的`Last-Modified`的值，服务器进行比较，如果相同则返回304，否则浏览器直接从服务器加载资源时，`Last-Modified`的`Header`在重新加载的时候会被更新，下次请求时，`If-Modified-Since`会启用上次返回的`Last-Modified`值
      
      - `Etag/If-None-Match`: 服务器会为每个资源生成一个唯一的标识字符串，只要文件内容不同，它们对应的 `Etag` 就是不同的；`If-Modified-Since`能检查到的精度是`s`级的，某些服务器不能精确的得到文件的最后修改时间，我们编辑了文件，但文件的内容没有改变。因为服务器是根据文件的最后修改时间来判断的，导致重新请求所以才出现了`Etag`，`Etag`对服务器也有性能损耗`Last-Modified`与`ETag`是可以一起使用的，服务器会优先验证`ETag`，一致的情况下，才会继续比对`Last-Modified`，最后才决定是否返回`304`。

        ![](/images/2020-11-30-20-40-29.png)

    + `memory cache` 与 `disk cache`
      - `from memory cache`代表使用内存中的缓存，`from disk cache`则代表使用的是硬盘中的缓存，浏览器读取缓存的顺序为`memory `–> `disk`。在浏览器中，浏览器会在`js`和图片等文件解析执行后直接存入内存缓存中，那么当刷新页面时只需直接从内存缓存中读取(`from memory cache`)；而`css`文件则会存入硬盘文件中，所以每次渲染页面都需要从硬盘读取缓存(`from disk cache`)。

    + `CDN`缓存
      - `CDN`缓存一般是由网站管理员自己部署，为了让他们的网站更容易扩展并获得更好的性能。通常情况下，浏览器先向`CDN`网关发起`Web`请求，网关服务器后面对应着一台或多台负载均衡源服务器，会根据它们的负载请求，动态将请求转发到合适的源服务器上。从浏览器角度来看，整个`CDN`就是一个源服务器，从这个层面来说，浏览器和服务器之间的缓存机制，在这种架构下同样适用

    + 应用缓存
      - `Cookie`：同一个域名下的所有请求，都会携带 `Cookie`，大小限制`4kb`
      - `Session Storage`：用来存储生命周期和它同步的会话级别的信息，关闭浏览器就不存在
      - `Local Storage`：持久化缓存 `5-10Mb`

+ 离线存储技术

    + [Service Worker缓存](https://segmentfault.com/a/1190000012353473)：在第一次访问后，后续即使没有网络连接，也能从缓存中获取页面必要的资源

----

## 渲染层面

### 浏览器的渲染机制

![](/images/2020-12-01-09-53-44.png)

浏览器整个流程如上图所示：

1. 当用户输入一个`URL`时，浏览器就会向服务器发出一个请求，请求`URL`对应的资源
2. 服务器返回一个HTML文件给浏览器的时候，浏览器接受到的是一些字节数据，浏览器根据`HTTP`响应中的编码方式（通过是`UTF8`），解析字节数据，得到一些字符。如果这个时候编码方式跟文件的字节编码不一致，便会出现乱码。所以我们通过使用`<meta http-equiv="content-type"content="text/html;charset=utf-8">`来告诉浏览器我们页面使用的是什么编码。浏览器再根据`DTD`中的对元素（标签）的定义，对这些接受到的字符进行语义化(`token`)。浏览器再使用这些语义块(token)创建对象，形成一个个节点了。然后HTML解析器就会从HTML文件的头部到尾部，一个个地遍历这些节点。整个流程可以概括为" 字节`Bytes` → 字符`characters` → 语义化`tokens` → 节点`nodes` → 树`object model` " 这样的方式生成最终的数据，
3. 若节点是普通节点，则会解析成一棵`DOM`树，`DOM`树的构建是一个**深度遍历**的过程，当前节点的所有子节点都构建完成以后，才会去构建当前节点的下一个兄弟节点。
4. 若是节点是CSS代码，则会将`CSS`解析成`CSSOM`树（`CSS Rule Tree`）
5. 根据`DOM`树和`CSSOM`树，来构建`Render Tree`（渲染树）,注意渲染树，并不等于`DOM`树，因为一些像`head`或`display:none`的东西，就没有必要放在渲染树中了。
6. 有了`Render Tree`，浏览器已经能知道网页中有哪些节点，各个节点的`CSS`定义，以及它们的从属关系，下一步操作就是`Layout`,顾名思义，就是计算出每个节点在屏幕中的位置。
7. `Layout`后，浏览器已经知道哪些节点要显示，每个节点的`CSS`属性是什么，每个节点在屏幕中的位置是哪里，就进入了最后一步`painting`,按照算出来的规则，通过显卡，把内容画到屏幕上。
8. 当某个元素的不会影响布局的属性被改变时候，会引起重绘（`Repaint`）；当布局发送变化时，则会引起重排（`Reflow`），重新计算`Render Tree`，重排的时候也会引起重绘。

+ 重绘 `Repaint`

  - 改变某个元素的背景色、文字颜色、边框颜色等等不影响它周围或内部布局的属性时，屏幕的一部分要重画，但是元素的几何尺寸没有变。

+ 重排 `Reflow`

  - 元件的几何尺寸变了，我们需要重新验证并计算`Render Tree`。是`Render Tree`的一部分或全部发生了变化。

  - `reflow` 几乎是无法避免的。现在界面上流行的一些效果，比如树状目录的折叠、展开（实质上是元素的显 示与隐藏）等，都将引起浏览器的 `reflow`。鼠标滑过、点击......只要这些行为引起了页面上某些元素的占位面积、定位方式、边距等属性的变化，都会引起它内部、周围甚至整个页面的重新渲染。通常我们都无法预估浏览器到底会 `reflow` 哪一部分的代码，它们都彼此相互影响着。

注：`display:none`会触发`reflow`，而`visibility:hidden`只会触发`repaint`，因为没有发现位置变化。

#### CSS性能方案


#### JS性能方案

### DOM优化

#### 原理与基本思路

#### 事件循环与异步更新

- 事件节流与消抖

#### 回流与重绘

### 首屏渲染提速

- 懒加载初探

----

## 性能监测

### 可视化工具

- Performance

- LightHouse

### W3C性能API

----

## 参考文献：

- [前端性能优化（一）](https://www.jianshu.com/p/2e69e9891c67)
- [简述浏览器渲染机制](https://www.jianshu.com/p/05eb1b17b298)